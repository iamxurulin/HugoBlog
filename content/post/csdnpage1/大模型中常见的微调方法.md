---
title: "大模型中常见的微调方法"
date: 2026-01-18 16:26:29
categories:
- AI
tags:
- 大模型
draft: false
---

Fine-tuning大模型微调指的是在**预训练模型**的基础上，使用特定的数据对模型进行**再训练**，以适应特定应用场景的需求。

常见的微调方法分为**全量微调**、**参数高效微调**以及**量化与混合微调**这三类。

## 全量微调

全量微调是直接对预训练模型中的**所有参数**进行再训练，使模型适应特定任务或者领域的需求，这种方式可以获得最佳的任务性能，不过缺点也很明显，因为是对所有参数再次训练，所以计算和存储的开销极大。

## 参数高效微调（Parameter-Efficient Fine-tuning，PEFT）
参数高效微调只更新少量的参数，从而大幅度降低训练和存储的成本。

有以下6种方法：



 1. Adapter Tuning` 是在`Transformer`每层中插入小模块，只训练Adapter。
    
    
 2. `LoRA（Low Rank Adaptation）`为每层添加低秩分解矩阵，然后只对这些 矩阵进行训练，是目前最流行的一种PEFT方法。
    
 3. `Prefix Tuning`在输入前加入可训练的`prefix tokens`，模型本体权重完全冻结。

    

 4. `Prompt Tuning`只训练用于任务提示的嵌入向量，不改变模型的内部结构，以提示的形式引导模型的行为。

    
  

 5. `P-Tuning`通过可学习的伪提示目标来优化。

    

6. `BitFit`只更新bias参数，训练参数占比通常小于0.1%。

## 量化与混合微调
`QLoRA`结合了`4-bit`量化、`LoRA`、双量化和分页优化器，利用低精度存储与低秩适配，单卡就能对百亿级模型进行微调。

`IR -QLoRA`在量化阶段引入**信息保留机制**与**弹性联结**，进一步减少了量化带来的性能损耗。
